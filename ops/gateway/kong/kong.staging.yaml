# Specific overrides for our `staging` environment

env:
  headers: "server_tokens, latency_tokens"

proxy:
  loadBalancerIP: 34.136.18.163

ingressController:
  args:
    [
      "–-anonymous-reports=false",
      "–-log-level=trace",
      "–-log-format=json",
      "–-profiling=true",
    ]

image:
  repository: gcr.io/voice-service-2-313121/kong-staging@sha256
  tag: 86870350684e7446fc0aa910415e158f35dba0220ec154ac43019496fbbf9943

resources:
  # TODO: refine limits after we perform some load testing
  limits:
    cpu: 2000m
    memory: 2048Mi
  requests:
    cpu: 1000m
    memory: 1024Mi

replicaCount: 1

autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 3
  ## Otherwise for clusters that do support autoscaling/v2beta, use metrics
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 75
