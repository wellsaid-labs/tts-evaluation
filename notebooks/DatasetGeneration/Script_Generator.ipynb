{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📄,📄,📄 -> 📄\n",
    "\n",
    "In this notebook, we'll compile individual, 10-minute voice acting scripts for our voice actors to read. We'll be selecting individual prompts from our Wikipedia, Edge Studio, and CMU Arctic sources and compiling them into our script template. Therefore before executing this notebook, it is important to populate `edge-studio/csv-source/` and `wikipedia/csv-source/` via the `Edge Studio Scraper.ipynb` and `Wikipedia Scraper.ipynb` notebooks.\n",
    "\n",
    "A 10-minute script includes a total of around 1,500 words (we're targetting a 150 WPM reading pace).\n",
    "\n",
    "To make things simple, we divide our 10 minute script into four 2.5 minute scripts which are auto-generated and appended together to form a full 10 minute script.\n",
    "\n",
    "A 2.5 minute script should contain around 375 words and is structured as follows:\n",
    "\n",
    "| 2.5 Minute Script | \n",
    "|------------|\n",
    "|Edge Studio (131 words)|\n",
    "|CMU Arctic (21 words)| \n",
    "|Wikipedia (223 words)|\n",
    "\n",
    "They'll include a single Edge Studio prompt, 1-3 CMU prompts, and one or more Wikipedia prompts. An example 2.5 Minute Script might look like the following:\n",
    "\n",
    "|Source|Title|Content|\n",
    "|------|-----|-------|\n",
    "|Edge Studio|Leadership Training|Becoming a leader in your organization isn't easy...|\n",
    "|CMU |CMU |The boy ran quickly down the stairs.|\n",
    "|CMU |CMU |He would remember this day.|\n",
    "|Wikipedia |Business: Marketing |The marketing function of a business is responsible...|\n",
    "|Wikipedia |Emotional intelligence: History |The study of emotional intelligence began...|\n",
    "\n",
    "\n",
    "The reasoning behind how we've structured these scripts is described in detail [here].\n",
    "\n",
    "[here]: https://docs.google.com/document/d/19PJYGxjlljE1ByFKGLA3XIgwO_X0k_B7pJp5VbuC8fg/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "import random, os, re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Source Directories and Target Script Length\n",
    "\n",
    "We keep the full, original copies of source material in `csv-source/` folders.\n",
    "\n",
    "It won't be uncommon for us to have multiple source files (for example, each Wikipedia article is saved as an individual `.csv`), so, for simplicity, the first thing we'll do is combine all source files into a single `.csv`. This makes it much easier to understand the entire body of source text which we are pulling from.\n",
    "\n",
    "When we load up source data for the first time, they're imported from these directories into a `DataFrame`.\n",
    "\n",
    "For our Edge Studio scripts, for example, we'll load up the source file(s) in our `edge-studio/csv-source/` folder, save a copy (`Edge Studio Source.csv`) into the `edge-studio/` directory to serve as a reference point for what our original source looked like. \n",
    "\n",
    "The file will be modified throughout the process of generating our script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGE_STUDIO_SOURCE_NAME = \"Edge Studio\"\n",
    "EDGE_STUDIO_SOURCE_DIRECTORY = \"edge-studio/csv-source/\"\n",
    "\n",
    "CMU_SOURCE_NAME = \"CMU\"\n",
    "CMU_SOURCE_DIRECTORY = \"cmu-arctic/csv-source/\"\n",
    "\n",
    "WIKIPEDIA_SOURCE_NAME = \"Wikipedia\"\n",
    "WIKIPEDIA_SOURCE_DIRECTORY = \"wikipedia/csv-source/\"\n",
    "\n",
    "SCRIPT_EXPORT_DOC_DIRECTORY = \"scripts/docx/\"\n",
    "SCRIPT_EXPORT_CSV_DIRECTORY = \"scripts/csv/\"\n",
    "\n",
    "TARGET_SCRIPT_LENGTH = 375 # word count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_from_source_directory(source_name, directory=\"\"):\n",
    "    \"\"\" Returns a DataFrame that contains the data in every .csv file in the specified directory. \n",
    "    \n",
    "    Args:\n",
    "        source_name (str): The name of the source. Ex. \"Edge Studio\".\n",
    "        directory (str): A directory containing source data saved in \n",
    "                        our CSV format (['Index', 'Title', 'Content'])\n",
    "    Returns:\n",
    "        source_df (DataFrame): A DataFrame containing all rows from each .csv in directory.\n",
    "    \"\"\"\n",
    "    # TODO: Avoid using constants within functions, abstract out into a global constant or keyword default\n",
    "    source_df  = pd.DataFrame(columns=['Source', 'Title', 'Content'])\n",
    "    \n",
    "    for file in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        if os.path.isfile(file_path) and file_path.lower().endswith('.csv'):\n",
    "            file_as_df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "            file_as_df['Source'] = source_name # add \"Source\" column\n",
    "            source_df  = source_df.append(file_as_df, ignore_index=True, sort=False)\n",
    "        else:\n",
    "            print('Did not import %s' % file_path)\n",
    "            \n",
    "    return source_df\n",
    "\n",
    "\n",
    "def create_master_dataframe_from_sources(sources_and_directories):\n",
    "    \"\"\" Returns a DataFrame that contains the data in every .csv file in the specified directories. \n",
    "    \n",
    "    Args:\n",
    "        sources_and_directories (dict): Dictionary containing names of sources and\n",
    "        corresponding directory. Ex. {\"Wikipedia\": \"wikipedia/csv-source/\"}.\n",
    "    Returns:\n",
    "        master_df (DataFrame): A DataFrame containing all rows from each .csv in directory.\n",
    "    \"\"\"\n",
    "    # TODO: Avoid using constants within functions, abstract out into a global constant or keyword default\n",
    "    master_df = pd.DataFrame(columns=['Source', 'Title', 'Content'])\n",
    "    \n",
    "    for key, value in sources_and_directories.items():\n",
    "        new_df = create_dataframe_from_source_directory(source_name=key,\n",
    "                                                        directory=value)\n",
    "        master_df = master_df.append(new_df, ignore_index=True, sort=False)\n",
    "    \n",
    "    return master_df\n",
    "\n",
    "\n",
    "def load_csv_as_dataframe(path):\n",
    "    return pd.read_csv(path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "\n",
    "def count_words(s):\n",
    "    list = re.findall(\"(\\S+)\", s) # Finds all non-whitespace patterns\n",
    "    return len(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load All Prompts Into Single Source\n",
    "\n",
    "Below, we'll load all of our Edge Studio, CMU, and Wikipedia source files into a single, master `DataFrame` named `master_df`.\n",
    "\n",
    "`master_df` serves a sort of central database containing our entire corpus of prompts across all sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>2 Virtual Tour/E-Learning Scripts</td>\n",
       "      <td>Morton Arboretum\\n\\nWelcome to Morton Arboretu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>2 Virtual Tours/Morton Arboretum</td>\n",
       "      <td>2 Virtual Tour/E-Learning Scripts\\nMorton Arbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>A Haunting Title</td>\n",
       "      <td>In this world, there is real evil.\\nIn the dar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>A story</td>\n",
       "      <td>Every moment has a story. And every story matt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>A Story</td>\n",
       "      <td>Every moment has a story. And every story matt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>A&amp;E Fashion Special</td>\n",
       "      <td>If you're in the market to liven up your décor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Abiogenic Theory</td>\n",
       "      <td>The abiogenic theory holds that hydrocarbons w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Adopted Children Seeking Biological Parents</td>\n",
       "      <td>Adopted Children Seeking Biological Parents\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Adopted Children Seeking Biological Parents</td>\n",
       "      <td>It is natural for an adopted child to be curio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Adopted Children Seeking Birth Parents</td>\n",
       "      <td>Adopted children are naturally curious about t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Air Processor 2000</td>\n",
       "      <td>To install a new capsule into your air purifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Alexander Solzhenitsyn Nobel Lecture (Excerpt)</td>\n",
       "      <td>A work of art contains its verification in its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>AllState Insurance</td>\n",
       "      <td>Congratulations, you just bought Allstate Home...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Alltel's 401k Plan</td>\n",
       "      <td>If the concept of long-term investing is new t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>American Airlines</td>\n",
       "      <td>Welcome aboard American Airlines coast-to-coas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>American Life Investment -personal Finance</td>\n",
       "      <td>Even if you’re in the second half of your life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Amica Life Insurance</td>\n",
       "      <td>In the next fifteen minutes, you will learn th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Apex</td>\n",
       "      <td>This “how to” video is designed to teach you h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Availability</td>\n",
       "      <td>Availability of business applications is requi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Availability</td>\n",
       "      <td>Availability\\nAvailability of business applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Baby Massage</td>\n",
       "      <td>This video is for parents…and grandparents…and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>The bacteria are assigned to the kingdom Moner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Ballroom Dancing</td>\n",
       "      <td>Just as you can’t run without first learning h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Bank Employee Training Web Video</td>\n",
       "      <td>When you first open a Client Interaction, you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Basketball Video</td>\n",
       "      <td>Nothing is more frustrating for a basketball p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Beginning Scuba</td>\n",
       "      <td>During open water certification, a scuba diver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Berlitz - The German Coast Guard</td>\n",
       "      <td>Improve your English.\\n\\nBerlitz\\n\\nLanguage f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Bicycle</td>\n",
       "      <td>) A bicycle can be among a runner’s most valua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Biogenetic Law</td>\n",
       "      <td>Commonly summarized as “ontogeny recapitulates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>Blue Angels</td>\n",
       "      <td>Strap yourself in for a high-altitude, history...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Policy: Content</td>\n",
       "      <td>Policies are typically promulgated through off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Policy: Typologies</td>\n",
       "      <td>The American political scientist Theodore J. L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Policy: Distributive policies</td>\n",
       "      <td>Distributive policies extend goods and service...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Policy: Regulatory policies</td>\n",
       "      <td>Regulatory policies, or mandates, limit the di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Policy: Constituent policies</td>\n",
       "      <td>Constituent policies create executive power en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Policy: Redistributive policies</td>\n",
       "      <td>Policies are dynamic; they are not just static...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Policy: Other uses of the term</td>\n",
       "      <td>In enterprise architecture for systems design,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Succession planning: Summary</td>\n",
       "      <td>Succession planning is a process for identifyi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Succession planning: Business succession planning</td>\n",
       "      <td>Organizations use succession planning as a pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Succession planning: Process and practices</td>\n",
       "      <td>Companies devise elaborate models to character...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Succession planning: Succession management</td>\n",
       "      <td>A substantial body of literature discusses suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Succession planning: Succession advisors</td>\n",
       "      <td>A prior preparation needs to be done for the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Succession planning: Business Exit Planning</td>\n",
       "      <td>With the global proliferation of SMEs, issues ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Succession planning: Family business</td>\n",
       "      <td>Small business succession tends to focus on ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Character orientation: Summary</td>\n",
       "      <td>Character orientation is how people relate to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Character orientation: History</td>\n",
       "      <td>German-American psychoanalyst Erich Fromm was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Character orientation: Receptive orientation</td>\n",
       "      <td>They receive satisfaction from outside factors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Character orientation: Exploitative orientation</td>\n",
       "      <td>Exploitative-oriented people aggressively take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Character orientation: Hoarding orientation</td>\n",
       "      <td>Hoarding-oriented people save what they alread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Character orientation: Marketing orientation</td>\n",
       "      <td>People who are marketing orientated see themse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Character orientation: Productive orientation</td>\n",
       "      <td>There is a healthy personality as well, which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>People skills: Summary</td>\n",
       "      <td>People skills are patterns of behavior and beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>People skills: History</td>\n",
       "      <td>Records of guidelines related to \"people skill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>People skills: Business impact</td>\n",
       "      <td>The SCANS report states that business, labor a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>People skills: Educational Importance</td>\n",
       "      <td>The Collaborative for Academic Social and Emot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Social intelligence: Summary</td>\n",
       "      <td>Social intelligence, the capacity to know ones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Social intelligence: Hypothesis</td>\n",
       "      <td>The social intelligence hypothesis states that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Social intelligence: Measurement</td>\n",
       "      <td>The social intelligence quotient is a statisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Social intelligence: Differences from intellig...</td>\n",
       "      <td>Nicholas Humphrey points to a difference betwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Social intelligence: Additional views</td>\n",
       "      <td>Social intelligence is closely related to cogn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2222 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Source                                              Title  \\\n",
       "0     Edge Studio                  2 Virtual Tour/E-Learning Scripts   \n",
       "1     Edge Studio                   2 Virtual Tours/Morton Arboretum   \n",
       "2     Edge Studio                                   A Haunting Title   \n",
       "3     Edge Studio                                            A story   \n",
       "4     Edge Studio                                            A Story   \n",
       "5     Edge Studio                                A&E Fashion Special   \n",
       "6     Edge Studio                                   Abiogenic Theory   \n",
       "7     Edge Studio        Adopted Children Seeking Biological Parents   \n",
       "8     Edge Studio        Adopted Children Seeking Biological Parents   \n",
       "9     Edge Studio             Adopted Children Seeking Birth Parents   \n",
       "10    Edge Studio                                 Air Processor 2000   \n",
       "11    Edge Studio     Alexander Solzhenitsyn Nobel Lecture (Excerpt)   \n",
       "12    Edge Studio                                 AllState Insurance   \n",
       "13    Edge Studio                                 Alltel's 401k Plan   \n",
       "14    Edge Studio                                  American Airlines   \n",
       "15    Edge Studio         American Life Investment -personal Finance   \n",
       "16    Edge Studio                               Amica Life Insurance   \n",
       "17    Edge Studio                                               Apex   \n",
       "18    Edge Studio                                       Availability   \n",
       "19    Edge Studio                                       Availability   \n",
       "20    Edge Studio                                       Baby Massage   \n",
       "21    Edge Studio                                           Bacteria   \n",
       "22    Edge Studio                                   Ballroom Dancing   \n",
       "23    Edge Studio                   Bank Employee Training Web Video   \n",
       "24    Edge Studio                                   Basketball Video   \n",
       "25    Edge Studio                                    Beginning Scuba   \n",
       "26    Edge Studio                   Berlitz - The German Coast Guard   \n",
       "27    Edge Studio                                            Bicycle   \n",
       "28    Edge Studio                                     Biogenetic Law   \n",
       "29    Edge Studio                                        Blue Angels   \n",
       "...           ...                                                ...   \n",
       "2192    Wikipedia                                    Policy: Content   \n",
       "2193    Wikipedia                                 Policy: Typologies   \n",
       "2194    Wikipedia                      Policy: Distributive policies   \n",
       "2195    Wikipedia                        Policy: Regulatory policies   \n",
       "2196    Wikipedia                       Policy: Constituent policies   \n",
       "2197    Wikipedia                    Policy: Redistributive policies   \n",
       "2198    Wikipedia                     Policy: Other uses of the term   \n",
       "2199    Wikipedia                       Succession planning: Summary   \n",
       "2200    Wikipedia  Succession planning: Business succession planning   \n",
       "2201    Wikipedia         Succession planning: Process and practices   \n",
       "2202    Wikipedia         Succession planning: Succession management   \n",
       "2203    Wikipedia           Succession planning: Succession advisors   \n",
       "2204    Wikipedia        Succession planning: Business Exit Planning   \n",
       "2205    Wikipedia               Succession planning: Family business   \n",
       "2206    Wikipedia                     Character orientation: Summary   \n",
       "2207    Wikipedia                     Character orientation: History   \n",
       "2208    Wikipedia       Character orientation: Receptive orientation   \n",
       "2209    Wikipedia    Character orientation: Exploitative orientation   \n",
       "2210    Wikipedia        Character orientation: Hoarding orientation   \n",
       "2211    Wikipedia       Character orientation: Marketing orientation   \n",
       "2212    Wikipedia      Character orientation: Productive orientation   \n",
       "2213    Wikipedia                             People skills: Summary   \n",
       "2214    Wikipedia                             People skills: History   \n",
       "2215    Wikipedia                     People skills: Business impact   \n",
       "2216    Wikipedia              People skills: Educational Importance   \n",
       "2217    Wikipedia                       Social intelligence: Summary   \n",
       "2218    Wikipedia                    Social intelligence: Hypothesis   \n",
       "2219    Wikipedia                   Social intelligence: Measurement   \n",
       "2220    Wikipedia  Social intelligence: Differences from intellig...   \n",
       "2221    Wikipedia              Social intelligence: Additional views   \n",
       "\n",
       "                                                Content  \n",
       "0     Morton Arboretum\\n\\nWelcome to Morton Arboretu...  \n",
       "1     2 Virtual Tour/E-Learning Scripts\\nMorton Arbo...  \n",
       "2     In this world, there is real evil.\\nIn the dar...  \n",
       "3     Every moment has a story. And every story matt...  \n",
       "4     Every moment has a story. And every story matt...  \n",
       "5     If you're in the market to liven up your décor...  \n",
       "6     The abiogenic theory holds that hydrocarbons w...  \n",
       "7     Adopted Children Seeking Biological Parents\\nI...  \n",
       "8     It is natural for an adopted child to be curio...  \n",
       "9     Adopted children are naturally curious about t...  \n",
       "10    To install a new capsule into your air purifie...  \n",
       "11    A work of art contains its verification in its...  \n",
       "12    Congratulations, you just bought Allstate Home...  \n",
       "13    If the concept of long-term investing is new t...  \n",
       "14    Welcome aboard American Airlines coast-to-coas...  \n",
       "15    Even if you’re in the second half of your life...  \n",
       "16    In the next fifteen minutes, you will learn th...  \n",
       "17    This “how to” video is designed to teach you h...  \n",
       "18    Availability of business applications is requi...  \n",
       "19    Availability\\nAvailability of business applica...  \n",
       "20    This video is for parents…and grandparents…and...  \n",
       "21    The bacteria are assigned to the kingdom Moner...  \n",
       "22    Just as you can’t run without first learning h...  \n",
       "23    When you first open a Client Interaction, you ...  \n",
       "24    Nothing is more frustrating for a basketball p...  \n",
       "25    During open water certification, a scuba diver...  \n",
       "26    Improve your English.\\n\\nBerlitz\\n\\nLanguage f...  \n",
       "27    ) A bicycle can be among a runner’s most valua...  \n",
       "28    Commonly summarized as “ontogeny recapitulates...  \n",
       "29    Strap yourself in for a high-altitude, history...  \n",
       "...                                                 ...  \n",
       "2192  Policies are typically promulgated through off...  \n",
       "2193  The American political scientist Theodore J. L...  \n",
       "2194  Distributive policies extend goods and service...  \n",
       "2195  Regulatory policies, or mandates, limit the di...  \n",
       "2196  Constituent policies create executive power en...  \n",
       "2197  Policies are dynamic; they are not just static...  \n",
       "2198  In enterprise architecture for systems design,...  \n",
       "2199  Succession planning is a process for identifyi...  \n",
       "2200  Organizations use succession planning as a pro...  \n",
       "2201  Companies devise elaborate models to character...  \n",
       "2202  A substantial body of literature discusses suc...  \n",
       "2203  A prior preparation needs to be done for the r...  \n",
       "2204  With the global proliferation of SMEs, issues ...  \n",
       "2205  Small business succession tends to focus on ho...  \n",
       "2206  Character orientation is how people relate to ...  \n",
       "2207  German-American psychoanalyst Erich Fromm was ...  \n",
       "2208  They receive satisfaction from outside factors...  \n",
       "2209  Exploitative-oriented people aggressively take...  \n",
       "2210  Hoarding-oriented people save what they alread...  \n",
       "2211  People who are marketing orientated see themse...  \n",
       "2212  There is a healthy personality as well, which ...  \n",
       "2213  People skills are patterns of behavior and beh...  \n",
       "2214  Records of guidelines related to \"people skill...  \n",
       "2215  The SCANS report states that business, labor a...  \n",
       "2216  The Collaborative for Academic Social and Emot...  \n",
       "2217  Social intelligence, the capacity to know ones...  \n",
       "2218  The social intelligence hypothesis states that...  \n",
       "2219  The social intelligence quotient is a statisti...  \n",
       "2220  Nicholas Humphrey points to a difference betwe...  \n",
       "2221  Social intelligence is closely related to cogn...  \n",
       "\n",
       "[2222 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Use constants for source names\n",
    "SOURCES_AND_DIRECTORIES = {\"Edge Studio\": EDGE_STUDIO_SOURCE_DIRECTORY,\n",
    "                           \"CMU\": CMU_SOURCE_DIRECTORY,\n",
    "                           \"Wikipedia\": WIKIPEDIA_SOURCE_DIRECTORY}\n",
    "\n",
    "master_df = create_master_dataframe_from_sources(SOURCES_AND_DIRECTORIES)\n",
    "\n",
    "display(master_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we can see that `master_df` contains all of the prompts found in our Edge Studio, CMU, and Wikipedia sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# edge_df = master_df.loc[master_df['Source'] == 'Edge Studio']\n",
    "# display(edge_df.head(3))\n",
    "\n",
    "# cmu_df = master_df.loc[master_df['Source'] == 'CMU'] \n",
    "# display(cmu_df.head(3))\n",
    "\n",
    "# wiki_df = master_df.loc[master_df['Source'] == 'Wikipedia'] \n",
    "# display(wiki_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Master `DataFrame` as  `.csv`\n",
    "\n",
    "It will be helpful to store a single `.csv` that contains the prompts from our combined sources. This can serve as a source of truth later if we're curious where our prompts were extracted from.\n",
    "\n",
    "We can also use this file as a starting point for future script generation if we only want to generate a small number of scripts now, update the file to remove the scripts we've used, and then reload and start another session later.\n",
    "\n",
    "The `.csv` format also allows us to share and explore our master source outside of `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \"Master Source\" doesn't mean much. save_formatted_dataframe() might be simpler/more straightforward\n",
    "# TODO: Create a util.py file that contains commonly-used functions like saving to csv. Then, import into notebooks.\n",
    "def save_dataframe_as_master_source(df, directory=\"\", filename=\"Master Source.csv\"):\n",
    "    df.to_csv(path_or_buf= \"%s%s\" % (directory, filename),\n",
    "              sep=\"\\t\",\n",
    "              index=True,\n",
    "              index_label=\"Index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataframe_as_master_source(master_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Single 2.5-Minute Script\n",
    "\n",
    "First, we'll define a function that searches for prompts of a specific length.\n",
    "\n",
    "This will be particularly useful as we search for Wikipedia prompts of varying lengths to ensure our full scripts are within a target word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_content_of_length(source_df, target_word_count, source=None, margin=.5):\n",
    "    \"\"\" Returns the first row of a DataFrame whose 'Content' column is within a desired word count.\n",
    "    \n",
    "    Args:\n",
    "        source_df (DataFrame): DataFrame containing prompts.\n",
    "        target_word_count (int): Desired length of 'Content'.\n",
    "        source (string): Name of source if we only want to search prompts Ex. \"Edge Studio\".\n",
    "        margin (float): % range that sets the upper/lower boundaries of word count.\n",
    "    Returns:\n",
    "        row (Series): The first row in df that fits the criteria. \n",
    "    \"\"\"    \n",
    "    lower_b = round(target_word_count * (1-margin))\n",
    "    upper_b = round(target_word_count * (1+margin))\n",
    "    \n",
    "    if source:\n",
    "        source_df = source_df.loc[source_df['Source'] == source]\n",
    "        \n",
    "    for index, row in source_df.iterrows():\n",
    "        if count_words(row['Content']) in range(lower_b, upper_b):\n",
    "            return row\n",
    "    \n",
    "    # adjust search and look for 2 prompts of half our target length...\n",
    "    lower_b = round(lower_b/2)\n",
    "    upper_b = round(upper_b/2)\n",
    "    \n",
    "    # create a DataFrame to store multiple prompts\n",
    "    results_df = pd.DataFrame(columns=['Source', 'Title', 'Content'])\n",
    "    for index, row in source_df.iterrows():\n",
    "        if count_words(row['Content']) in range(lower_b, upper_b):\n",
    "            results_df = results_df.append(row, ignore_index=True, sort=False)            \n",
    "        if len(results_df.index) == 2:\n",
    "            return results_df\n",
    "        \n",
    "    raise Exception(\"Unable to find a %s prompt within %s and %s words...\" % (source, lower_b, upper_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define a function that generates a 2.5-minute script. As a reminder, each 2.5-minute script should contain around 375 words and is structured as follows:\n",
    "\n",
    "| 2.5 Minute Script | \n",
    "|------------|\n",
    "|Edge Studio Prompt (131 words)|\n",
    "|1-3 CMU Arctic Prompt(s) (21 words)| \n",
    "|Wikipedia Prompt(s) (223 words)|\n",
    "\n",
    "Given a `DataFrame` containing all of our source material and a target word count for our 2.5-minute script, we execute the following steps to generate a 2.5-minute script:\n",
    "1. The first available Edge Studio prompt is selected.\n",
    "2. The first available 1-3 CMU prompts are selected.\n",
    "3. The remaining word count for the script is calculated.\n",
    "4. Wikipedia prompt(s) that fill the remaining word count are selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_script(source_df, word_count):\n",
    "    \"\"\" Returns a DataFrame containing a 2.5-minute script containg prompts from a given \n",
    "        source DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        source_df (DataFrame): DataFrame containing Edge Studio, CMU, and Wikipedia prompts.\n",
    "        word_count(int): Desired length (number of words) of resulting script.\n",
    "    Returns:\n",
    "        short_script_df (DataFrame): A DataFrame containing prompts for a 2.5-minute script. \n",
    "    \"\"\"\n",
    "    # TODO: Use constants for source names\n",
    "    short_script_df = pd.DataFrame(columns=['Source', 'Title', 'Content'])\n",
    "    \n",
    "    # 1. Edge Studio\n",
    "    edge_df = source_df.loc[source_df['Source'] == 'Edge Studio'] # get all Edge Studio prompts\n",
    "    selected_edge_prompt = edge_df.iloc[0] # select single row\n",
    "    short_script_df = short_script_df.append(selected_edge_prompt, ignore_index=True) # append\n",
    "    \n",
    "    # 2. CMU\n",
    "    cmu_df = source_df.loc[source_df['Source'] == 'CMU']\n",
    "    # TODO: Use constants for range values. Ex. CMU_ROW_MIN, CMU_ROW_MAX\n",
    "    num_rows = random.randint(1,3)\n",
    "    selected_cmu_prompts = cmu_df.iloc[0:num_rows]\n",
    "    short_script_df = short_script_df.append(selected_cmu_prompts, ignore_index=True)\n",
    "    \n",
    "    # 3. Determine desired word count of Wikipedia prompt(s)\n",
    "    word_count_so_far = 0\n",
    "    for index, row in short_script_df.iterrows():\n",
    "        words_in_prompt = count_words(row['Content'])\n",
    "        word_count_so_far += words_in_prompt\n",
    "    remaining_words = word_count - word_count_so_far\n",
    "    \n",
    "    # 4. Wikipedia\n",
    "    if remaining_words > 10: # only search for Wiki prompts if we need them....\n",
    "        selected_wiki_prompt = find_content_of_length(source_df, remaining_words, source=\"Wikipedia\")\n",
    "        short_script_df = short_script_df.append(selected_wiki_prompt, ignore_index=True)\n",
    "\n",
    "    return short_script_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_script_df = generate_script(source_df=master_df,\n",
    "                                   word_count=TARGET_SCRIPT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Sample 2.5 Minute Script"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>2 Virtual Tour/E-Learning Scripts</td>\n",
       "      <td>Morton Arboretum\\n\\nWelcome to Morton Arboretu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMU</td>\n",
       "      <td>CMU</td>\n",
       "      <td>Author of the danger trail, Philip Steels, etc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Problem solving: Definition</td>\n",
       "      <td>The term problem solving is used in numerous d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source                              Title  \\\n",
       "0  Edge Studio  2 Virtual Tour/E-Learning Scripts   \n",
       "1          CMU                                CMU   \n",
       "2    Wikipedia        Problem solving: Definition   \n",
       "\n",
       "                                             Content  \n",
       "0  Morton Arboretum\\n\\nWelcome to Morton Arboretu...  \n",
       "1    Author of the danger trail, Philip Steels, etc.  \n",
       "2  The term problem solving is used in numerous d...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"### Sample 2.5 Minute Script\"))\n",
    "display(single_script_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Multiple Scripts\n",
    "\n",
    "2.5-minute scripts are our building blocks for longer scripts. They're the smallest unit of script we'll build from.\n",
    "\n",
    "To generate a 10-minute script, for example, we'll generate and append four 2.5-minute scripts.\n",
    "\n",
    "To generate a 1-hour script, we'll generate and append a total of 24 (4 * 6) 2.5-minute scripts. And so on...\n",
    "\n",
    "### Define Helper Function(s) To Help Generate Multiple Scripts\n",
    "\n",
    "Whenever we select a prompt to use in a 2.5-minute script, it's important we remove it from our `source_df` so that it's not re-used in a later script.\n",
    "\n",
    "Let's define a function that removes selected prompts from a given `source_df`.\n",
    "\n",
    "**Bonus points:** if our source happens to have multiple instances of a prompt we'd like to remove, this function will remove all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_script_prompts_from_source(source_df, script_df):\n",
    "    \"\"\" Returns a copy of source_df with the rows contained in script_df removed.\n",
    "    \n",
    "    Args:\n",
    "        source_df (DataFrame): DataFrame containing all source prompts.\n",
    "        script_df (DataFrame): DataFrame containing prompts that will be used in a script.\n",
    "    Returns:\n",
    "        source_df (DataFrame): A copy of source_df with any prompts found in script_df removed.\n",
    "    \"\"\"\n",
    "    for index, row in script_df.iterrows():\n",
    "        content = row['Content']\n",
    "        row_to_remove = source_df.loc[source_df['Content'] == content]\n",
    "        source_df = source_df.drop(row_to_remove.index)\n",
    "    return source_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Multiple Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's put all of this together and define a function that generates and returns a script containing *multiple* 2.5-minute scripts.\n",
    "\n",
    "Our function will default to generating a 10-minute script (i.e. it will generate and append four 2.5-minute scripts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scripts(source_df, num_of_short_scripts=4):\n",
    "    \"\"\" Generates multiple short scripts, appends them, and returns the result as\n",
    "        a single DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        source_df (DataFrame): DataFrame containing source prompts.\n",
    "        num_of_short_scripts (int): Int specifying how many short (2.5-minute) scripts should be generated.\n",
    "    Returns:\n",
    "        long_script (DataFrame): DataFrame containing all requested short_scripts.\n",
    "    \"\"\"\n",
    "    long_script = pd.DataFrame(columns=['Source', 'Title', 'Content'])\n",
    "    \n",
    "    for i in range(num_of_short_scripts):\n",
    "        short_script = generate_script(source_df, TARGET_SCRIPT_LENGTH)\n",
    "        long_script = long_script.append(short_script, ignore_index=True)\n",
    "        source_df = remove_script_prompts_from_source(source_df, short_script)\n",
    "        \n",
    "    return long_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Long Script"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>2 Virtual Tour/E-Learning Scripts</td>\n",
       "      <td>Morton Arboretum\\n\\nWelcome to Morton Arboretu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMU</td>\n",
       "      <td>CMU</td>\n",
       "      <td>Author of the danger trail, Philip Steels, etc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMU</td>\n",
       "      <td>CMU</td>\n",
       "      <td>Not at this particular case, Tom, apologized W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Problem solving: Definition</td>\n",
       "      <td>The term problem solving is used in numerous d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>2 Virtual Tours/Morton Arboretum</td>\n",
       "      <td>2 Virtual Tour/E-Learning Scripts\\nMorton Arbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CMU</td>\n",
       "      <td>CMU</td>\n",
       "      <td>For the twentieth time that evening the two me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CMU</td>\n",
       "      <td>CMU</td>\n",
       "      <td>Lord, but I'm glad to see you again, Phil.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CMU</td>\n",
       "      <td>CMU</td>\n",
       "      <td>Will we ever forget it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Problem solving: Cognitive sciences</td>\n",
       "      <td>The early experimental work of the Gestaltists...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>A Haunting Title</td>\n",
       "      <td>In this world, there is real evil.\\nIn the dar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CMU</td>\n",
       "      <td>CMU</td>\n",
       "      <td>God bless 'em, I hope I'll go on seeing them f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Problem solving: Problem-solving strategies</td>\n",
       "      <td>Problem-solving strategies are the steps that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Edge Studio</td>\n",
       "      <td>A story</td>\n",
       "      <td>Every moment has a story. And every story matt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CMU</td>\n",
       "      <td>CMU</td>\n",
       "      <td>And you always want to see it in the superlati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Problem solving: Confirmation bias</td>\n",
       "      <td>Within the field of science there exists a set...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Source                                        Title  \\\n",
       "0   Edge Studio            2 Virtual Tour/E-Learning Scripts   \n",
       "1           CMU                                          CMU   \n",
       "2           CMU                                          CMU   \n",
       "3     Wikipedia                  Problem solving: Definition   \n",
       "4   Edge Studio             2 Virtual Tours/Morton Arboretum   \n",
       "5           CMU                                          CMU   \n",
       "6           CMU                                          CMU   \n",
       "7           CMU                                          CMU   \n",
       "8     Wikipedia          Problem solving: Cognitive sciences   \n",
       "9   Edge Studio                             A Haunting Title   \n",
       "10          CMU                                          CMU   \n",
       "11    Wikipedia  Problem solving: Problem-solving strategies   \n",
       "12  Edge Studio                                      A story   \n",
       "13          CMU                                          CMU   \n",
       "14    Wikipedia           Problem solving: Confirmation bias   \n",
       "\n",
       "                                              Content  \n",
       "0   Morton Arboretum\\n\\nWelcome to Morton Arboretu...  \n",
       "1     Author of the danger trail, Philip Steels, etc.  \n",
       "2   Not at this particular case, Tom, apologized W...  \n",
       "3   The term problem solving is used in numerous d...  \n",
       "4   2 Virtual Tour/E-Learning Scripts\\nMorton Arbo...  \n",
       "5   For the twentieth time that evening the two me...  \n",
       "6          Lord, but I'm glad to see you again, Phil.  \n",
       "7                             Will we ever forget it.  \n",
       "8   The early experimental work of the Gestaltists...  \n",
       "9   In this world, there is real evil.\\nIn the dar...  \n",
       "10  God bless 'em, I hope I'll go on seeing them f...  \n",
       "11  Problem-solving strategies are the steps that ...  \n",
       "12  Every moment has a story. And every story matt...  \n",
       "13  And you always want to see it in the superlati...  \n",
       "14  Within the field of science there exists a set...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "long_script_df = generate_scripts(master_df, num_of_short_scripts=4)\n",
    "\n",
    "display(Markdown(\"### Long Script\"))\n",
    "display(long_script_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export Script As Readable `.docx` File\n",
    "\n",
    "We'll use the `python-docx` [library] to export as script as a readable `.docx` file for our voice actor.\n",
    "\n",
    "It will also be helpful to save the script in a corresponding csv file in the (likely) event that we'll want to easily extract the prompts contained in the script later (or re-produce the docx file).\n",
    "\n",
    "[library]: http://python-docx.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Inches, RGBColor, Pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_script_as_docx(script_df, doc_title, doc_path='Script.docx', csv_path=\"Script.csv\"):\n",
    "    \n",
    "    document = Document()    \n",
    "   \n",
    "    # page title\n",
    "    p = document.add_heading(level=1)\n",
    "    r = p.add_run()\n",
    "    r.add_picture('ws_watermark.png', width=Inches(1))\n",
    "    r.add_break()\n",
    "    r.add_text(doc_title)\n",
    "    r.font.size = Pt(15)\n",
    "    r.font.name = 'Helvetica Neue'\n",
    "    r.font.bold = False\n",
    "    r.font.color.rgb = RGBColor(142, 142, 142)\n",
    "    r.add_break()\n",
    "    \n",
    "    # instructions\n",
    "    p = document.add_paragraph()\n",
    "    p.add_run('Style: ', 'Strong').font.name = 'Helvetica Neue'\n",
    "    p.add_run('E-Learning').font.name = 'Helvetica Neue'\n",
    "    p.add_run().add_break()\n",
    "    p.add_run('Instructions: ', 'Strong').font.name = 'Helvetica Neue'\n",
    "    p.add_run('Read black text, ignore green titles.').font.name = 'Helvetica Neue'\n",
    "    \n",
    "    # prompts\n",
    "    for index, row in script_df.iterrows():\n",
    "        # prompt title\n",
    "        p = document.add_heading(level=1)\n",
    "        r = p.add_run(row['Title'])\n",
    "        r.font.size = Pt(14)\n",
    "        r.font.name = 'Helvetica Neue'\n",
    "        r.font.color.rgb = RGBColor(51, 238, 114)\n",
    "        \n",
    "        # prompt body\n",
    "        p = document.add_paragraph()\n",
    "        r = p.add_run(row['Content'])\n",
    "        r.font.size = Pt(12)\n",
    "        r.font.name = 'Helvetica Neue'\n",
    "        r.font.color.rgb = RGBColor(0, 0, 0)\n",
    "        \n",
    "    try:\n",
    "        document.save(doc_path) # write docx\n",
    "        script_df.to_csv(path_or_buf=csv_path, sep=\"\\t\",index=True, index_label=\"Index\") # write csv\n",
    "    except Exception as e:\n",
    "        print(\"Something went wrong while trying to export script!\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_name = \"Sample Script\"\n",
    "\n",
    "export_doc_path = \"%s%s.docx\" % (SCRIPT_EXPORT_DOC_DIRECTORY, script_name)\n",
    "export_csv_filename = \"%s%s.csv\" % (SCRIPT_EXPORT_CSV_DIRECTORY, script_name)\n",
    "\n",
    "export_script_as_docx(long_script_df, doc_title=script_name, doc_path=export_doc_path, csv_path=export_csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Drop Prompts From Master Source\n",
    "\n",
    "Now that we've selected some prompts to use in a voice acting script, we'll remove them from our source so that we avoid re-using them later.\n",
    "\n",
    "1. Remove selected prompts from source `DataFrame`\n",
    "2. Save new source `DataFrame` as our source `.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = remove_script_prompts_from_source(master_df, long_script_df)\n",
    "\n",
    "save_dataframe_as_master_source(master_df)\n",
    "\n",
    "# display(master_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Add Final Helper Functions...\n",
    "If we need to generate a total of 20 hours of voice acting scripts, it'd be cumbersome to generate 120 (20\\*6) 10-minute scripts one at a time. Soon, we'll write a loop that generates multiple, individual 10-minute scripts.\n",
    "\n",
    "But, first, there's one final set of helper functions we'll want to write.\n",
    "\n",
    "Some of the Wikipedia prompts in our source data can be too long to use in their entirety (300+ words), but we'd be able to use them if we split them up into smaller pieces.\n",
    "\n",
    "We'll write the functionality to locate Wikipedia prompts in our source data, split them up by line break, and save each new, shorter prompt as a new row in our source data.\n",
    "\n",
    "### Wiki Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string(s, sep=\"\\n\"):\n",
    "    \"\"\"Splits a string on a separator, removes any empty space, \n",
    "    and returns a list of resulting string(s).\"\"\"\n",
    "    result = []\n",
    "    for line in s.split(sep):\n",
    "        if line.replace(\" \", \"\"):\n",
    "            result.append(line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before:** `'Business is so awesome.\\n\\nMaking money is good.\\nYay, business!'`\n",
    "\n",
    "**After:** `['Business is so awesome.', 'Making money is good.', 'Yay, business!']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_wiki_row(wiki_row, sep=\"\\n\"):\n",
    "    \"\"\"Splits each row in a DataFrame into multiple rows using a \n",
    "    separator on the value found in the 'Content' column.\"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(columns=['Source', 'Title', 'Content'])\n",
    "    \n",
    "    source = wiki_row['Source']\n",
    "    title = wiki_row['Title']\n",
    "    content = wiki_row['Content']\n",
    "    \n",
    "    content_split = split_string(content, sep=sep)\n",
    "    len_of_split_content = len(content_split)\n",
    "    \n",
    "    if len_of_split_content == 1:\n",
    "        return wiki_row\n",
    "    else:\n",
    "        i = 1\n",
    "        for line in content_split:\n",
    "            row_title = '%s (%s/%s)' % (title, i, len_of_split_content)\n",
    "            formatted_row = {'Source': source, 'Title': row_title, 'Content': line}\n",
    "            df = df.append(formatted_row, ignore_index=True, sort=False)\n",
    "            i += 1\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before:**\n",
    "\n",
    "| Source | Title | Content | \n",
    "|--------|-------|---------|\n",
    "|Wikipedia|Business: Summary|Business is so awesome.\\n\\nMaking money is good.\\nYay, business!|\n",
    "\n",
    "**After:** \n",
    "\n",
    "| Source | Title | Content | \n",
    "|--------|-------|---------|\n",
    "|Wikipedia|Business: Summary (1/3)|Business is so awesome.|\n",
    "|Wikipedia|Business: Summary (2/3)|Making money is good.|\n",
    "|Wikipedia|Business: Summary (3/3)|Yay, business!|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_wiki_prompts(source_df, sep=\"\\n\"):\n",
    "    \"\"\" Returns a copy of source_df with the Wikipedia prompts split up by line breaks (sep).\n",
    "    \n",
    "    Args:\n",
    "        source_df (DataFrame): DataFrame containing all source prompts.\n",
    "        sep (str): The value to split Wikipedia prompts by. Defaults to '\\n.'\n",
    "    Returns:\n",
    "        source_df (DataFrame): A copy of source_df with Wikipedia prompts that have been broken\n",
    "        up by the sep value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. extract edge, wiki, and cmu prompts\n",
    "    edge_df = source_df.loc[source_df['Source'] == 'Edge Studio']\n",
    "    wiki_df = source_df.loc[source_df['Source'] == 'Wikipedia']\n",
    "    cmu_df = source_df.loc[source_df['Source'] == 'CMU']\n",
    "    \n",
    "    result_df = edge_df\n",
    "    \n",
    "    # 2. split up wiki prompts\n",
    "    wiki_df_split = pd.DataFrame(columns=['Source', 'Title', 'Content'])\n",
    "    for index, row in wiki_df.iterrows():\n",
    "        # print(\"Splitting row: %s\" % row)\n",
    "        row_split = split_wiki_row(row)\n",
    "        wiki_df_split = wiki_df_split.append(row_split, ignore_index=True, sort=False)\n",
    "\n",
    "    # 3. append wiki\n",
    "    result_df = result_df.append(wiki_df_split, ignore_index=True, sort=False)\n",
    "    \n",
    "    # 4. append CMU\n",
    "    result_df = result_df.append(cmu_df, ignore_index=True, sort=False)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting It All Together: Generating Multiple 10-Minute Scripts\n",
    "\n",
    "And, finally, we'll write a loop that generates multiple, individual 10-minute scripts. The process is straightforward:\n",
    "\n",
    "1. The source prompts are loaded\n",
    "2. A 10-minute script is generated\n",
    "3. The script is exported as a `.csv` and `.docx`\n",
    "4. The prompts from the script are removed from the source prompts\n",
    "5. The revised source prompts are saved (and will be used as the source in the next run)\n",
    "\n",
    "We set the desired number of scripts to generate with the `TOTAL` variable.\n",
    "\n",
    "After each script is generated, the prompts are removed from the source data and the new source data is saved as a `.csv`. This serves as a checkpoint to which we can later return if needed.\n",
    "\n",
    "In the run below, we'll generate six 10-minute scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTING_SCRIPT_NUM = 1\n",
    "TOTAL = 6\n",
    "VO_ACTOR = \"Alicia\"\n",
    "CURRENT_SCRIPT_NUM = STARTING_SCRIPT_NUM\n",
    "\n",
    "for i in range(0,TOTAL):\n",
    "\n",
    "    # 1. load source prompts\n",
    "    if CURRENT_SCRIPT_NUM == 1:\n",
    "        # if this is the first-ever script for a data source, generate source data from source directories\n",
    "        master_source_df = create_master_dataframe_from_sources(SOURCES_AND_DIRECTORIES)\n",
    "        save_dataframe_as_master_source(master_source_df, \n",
    "                                        filename=\"Master Source - %s %s.csv\" % (VO_ACTOR, CURRENT_SCRIPT_NUM - 1))\n",
    "    else:\n",
    "        # otherwise, load the data from the last checkpoint\n",
    "        master_source_df = load_csv_as_dataframe('Master Source - %s %s.csv' % (VO_ACTOR, (CURRENT_SCRIPT_NUM -1)))\n",
    "\n",
    "    # (optional) if we're unable to find wikipedia prompts, try splitting the source DF wiki rows\n",
    "    # master_source_df = split_wiki_prompts(source_df=master_source_df)\n",
    "\n",
    "    # 2. generate scripts\n",
    "    scripts_df = generate_scripts(master_source_df, num_of_short_scripts=4)\n",
    "\n",
    "    # 3. save scripts to docx, csv\n",
    "    script_name = \"Script %s - %s\" % (CURRENT_SCRIPT_NUM, VO_ACTOR)\n",
    "    export_doc_path = \"%s%s.docx\" % (SCRIPT_EXPORT_DOC_DIRECTORY, script_name)\n",
    "    export_csv_filename = \"%s%s.csv\" % (SCRIPT_EXPORT_CSV_DIRECTORY, script_name)\n",
    "    export_script_as_docx(scripts_df, \n",
    "                          doc_title=\"Script %s\" % CURRENT_SCRIPT_NUM, \n",
    "                          doc_path=export_doc_path,\n",
    "                          csv_path=export_csv_filename)\n",
    "\n",
    "    # 4. remove prompts from master prompts source\n",
    "    master_df = remove_script_prompts_from_source(master_source_df, scripts_df)\n",
    "\n",
    "    # 5. save revised master source as csv\n",
    "    save_dataframe_as_master_source(master_df, filename=\"Master Source - %s %s.csv\" % (VO_ACTOR, CURRENT_SCRIPT_NUM))\n",
    "    \n",
    "    CURRENT_SCRIPT_NUM += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to generate more scripts starting from where we left off, we'd change `STARTING_SCRIPT_NUM` to the number of the last script we generated (in the loop above, this would be `6`). This will load the data source at the last checkpoint and start generating scripts from there.\n",
    "\n",
    "The generated scripts can be found in the `/scripts` directory.\n",
    "\n",
    "\n",
    "`TODO (Improvements)`:\n",
    "- Wrap the loop above into a single function.\n",
    "- Automate the split_wiki_prompts() function.\n",
    "- Create a less intensive checkpointing process. Instead of saving a new `.csv` of the entire source data after each script is generated, save a single copy at the beginning of the run and then write a function that takes all of the individual script `.csv` files generated during a run and remove their prompts from the original master source `.csv`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
