import functools

from torch import nn
from tensorflow.contrib.signal.python.ops import window_ops
from torch.optim import Adam

from src.configurable import add_config
from src.configurable import configurable


def set_hparams():
    """ Using the ``configurable`` module set the hyperparameters for the source code.
    """

    Adam.__init__ = configurable(Adam.__init__)
    nn.modules.batchnorm._BatchNorm.__init__ = configurable(
        nn.modules.batchnorm._BatchNorm.__init__)
    add_config({
        # NOTE: `momentum=0.01` to match Tensorflow defaults
        'torch.nn.modules.batchnorm._BatchNorm.__init__': {
            'momentum': 0.01,
        },
        # SOURCE (Tacotron 2):
        # We use the Adam optimizer [29] with Î²1 = 0.9, Î²2 = 0.999, eps = 10âˆ’6
        # learning rate of 10âˆ’3
        # We also apply L2 regularization with weight 10âˆ’6
        'torch.optim.Adam.__init__': {
            'betas': (0.9, 0.999),
            'eps': 10e-6,
            'lr': 10e-3,
            'weight_decay': 10e-6,
        }
    })

    # SOURCE (Tacotron 2):
    # The convolutional layers in the network are regularized using dropout [25] with probability
    # 0.5, and LSTM layers are regularized using zoneout [26] with probability 0.1
    convolution_dropout = 0.5
    lstm_dropout = 0.1

    # Hidden size of the feature representation generated by encoder.
    encoder_hidden_size = 512

    # SOURCE (Tacotron 2):
    # 80 channel mel filterbank spanning
    frame_channels = 80

    # SOURCE (Tacotron 2):
    # The prediction from the previous time step is first passed through a small
    # pre-net containing 2 fully connected layers of 256 hidden ReLU units.
    pre_net_hidden_size = 256

    # SOURCE (Tacotron 2):
    # Attention probabilities are computed after projecting inputs and location
    # features to 128-dimensional hidden representations.
    attention_hidden_size = 128

    wav_to_log_mel_spectrogram = {
        # SOURCE (Tacotron 2):
        # mel spectrograms are computed through a shorttime Fourier transform (STFT)
        # using a 50 ms frame size, 12.5 ms frame hop, and a Hann window function.
        'frame_size': 50,
        'frame_hop': 12.5,
        'window_function': functools.partial(window_ops.hann_window, periodic=True),
        # SOURCE (Tacotron 2):
        # We transform the STFT magnitude to the mel scale using an 80 channel mel
        # filterbank spanning 125 Hz to 7.6 kHz, followed by log dynamic range
        # compression.
        'num_mel_bins': frame_channels,
        'lower_hertz': 125,
        'upper_hertz': 7600,
        # SOURCE (Tacotron 2):
        # Prior to log compression, the filterbank output magnitudes are clipped to a
        # minimum value of 0.01 in order to limit dynamic range in the logarithmic
        # domain.
        'min_magnitude': 0.01,
    }

    # SOURCE (Tacotron 1):
    # We use 24 kHz sampling rate for all experiments.
    sample_rate = 24000

    add_config({
        'src': {
            'lr_schedulers.DelayedExponentialLR.__init__': {
                # SOURCE (Tacotron 2):
                # learning rate of 10âˆ’3 exponentially decaying to 10âˆ’5 starting after 50,000
                # iterations.
                # NOTE: Over email the authors confirmed they ended decay at 100,000 steps
                'epoch_start_decay': 50000,
                'epoch_end_decay': 100000,
                'end_lr': 10e-5,
            },
            'spectrogram': {
                '_read_audio.sample_rate': sample_rate,
                'wav_to_log_mel_spectrogram': wav_to_log_mel_spectrogram,
                'log_mel_spectrogram_to_wav': {
                    'frame_size': wav_to_log_mel_spectrogram['frame_size'],
                    'frame_hop': wav_to_log_mel_spectrogram['frame_hop'],
                    'window_function': wav_to_log_mel_spectrogram['window_function'],
                    'lower_hertz': wav_to_log_mel_spectrogram['lower_hertz'],
                    'upper_hertz': wav_to_log_mel_spectrogram['upper_hertz'],
                    'sample_rate': sample_rate,
                    # SOURCE (Tacotron 1):
                    # We found that raising the predicted magnitudes by a power of 1.2 before
                    # feeding to Griffin-Lim reduces artifacts
                    'power': 1.20,
                },
            },
            'feature_model': {
                'encoder.Encoder.__init__': {
                    'lstm_dropout': lstm_dropout,
                    'convolution_dropout': convolution_dropout,

                    # SOURCE (Tacotron 2):
                    # Input characters are represented using a learned 512-dimensional character
                    # embedding
                    'embedding_dim': 512,

                    # SOURCE (Tacotron 2):
                    # which are passed through a stack of 3 convolutional layers each containing
                    # 512 filters with shape 5 Ã— 1, i.e., where each filter spans 5 characters
                    'num_convolution_layers': 3,
                    'num_convolution_filters': 512,
                    'convolution_filter_size': 5,

                    # SOURCE (Tacotron 2)
                    # The output of the final convolutional layer is passed into a single
                    # bi-directional [19] LSTM [20] layer containing 512 units (256) in each
                    # direction) to generate the encoded features.
                    'lstm_hidden_size': encoder_hidden_size,  # 512
                    'lstm_layers': 1,
                    'lstm_bidirectional': True,
                },
                'attention.LocationSensitiveAttention.__init__': {
                    'encoder_hidden_size': encoder_hidden_size,

                    # SOURCE (Tacotron 2):
                    # Attention probabilities are computed after projecting inputs and location
                    # features to 128-dimensional hidden representations.
                    'hidden_size': attention_hidden_size,

                    # SOURCE (Tacotron 2):
                    # Location features are computed using 32 1-D convolution filters of length
                    # 31.
                    'num_convolution_filters': 32,
                    'convolution_filter_size': 31,
                },
                'decoder.AutoregressiveDecoder.__init__': {
                    'frame_channels': frame_channels,
                    'pre_net_hidden_size': pre_net_hidden_size,
                    'encoder_hidden_size': encoder_hidden_size,
                    'lstm_dropout': lstm_dropout,
                    'attention_context_size': attention_hidden_size,

                    # SOURCE (Tacotron 2):
                    # The prenet output and attention context vector are concatenated and
                    # passed through a stack of 2 uni-directional LSTM layers with 1024 units.
                    'lstm_hidden_size': 1024,
                },
                'pre_net.PreNet.__init__': {
                    'frame_channels': frame_channels,

                    # SOURCE (Tacotron 2):
                    # The prediction from the previous time step is first passed through a small
                    # pre-net containing 2 fully connected layers of 256 hidden ReLU units.
                    'num_layers': 2,
                    'hidden_size': pre_net_hidden_size,
                    'nonlinearity': nn.ReLU,

                    # SOURCE (Tacotron 2):
                    # In order to introduce output variation at inference time, dropout with
                    # probability 0.5 is applied only to layers in the pre-net of the
                    # autoregressive decoder.
                    'dropout': 0.5,
                },
                'post_net.PostNet.__init__': {
                    'frame_channels': frame_channels,
                    'convolution_dropout': convolution_dropout,

                    # SOURCE (Tacotron 2):
                    # Finally, the predicted mel spectrogram is passed
                    # through a 5-layer convolutional post-net which predicts a residual
                    # to add to the prediction to improve the overall reconstruction
                    'num_convolution_layers': 5,

                    # SOURCE (Tacotron 2):
                    # Each post-net layer is comprised of 512 filters with shape 5 Ã— 1 with
                    # batch normalization, followed by tanh activations on all but the final
                    # layer
                    'num_convolution_filters': 512,
                    'convolution_filter_size': 5,
                },
                'model.SpectrogramModel.__init__': {
                    'encoder_hidden_size': encoder_hidden_size,
                    'frame_channels': frame_channels,
                }
            }
        }
    })
